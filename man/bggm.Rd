\name{bggm}
\alias{bggm}
\title{Bayesian Gaussian Graphical Models}
\description{
Fits some models based on the generalized approach to BGGMs proposed by Franco et al. (2024). The statistical fit is carried out by the `MCMC` or `LA` functions of the `YABS` package.
}
\usage{
bggm(data, reg=NULL, cor=NULL, sparse=NULL, est=NULL, full=FALSE, ...)
}
\arguments{
   \item{data}{The data frame or numeric matrix. If the data is ordered discrete, than the smallest possible value for each variable should be 0.}
   \item{reg}{The regularization prior that should be used. Defaults to "normal". The other possible values are: "normal", "laplace", "logistic", "cauchy", "hypersec", "t", "lomax", "kaniadakis", and "NEG". For more details regarding these priors, see: https://doi.org/10.56296/aip00022}
   \item{cor}{The type of correlation to be estimated. Defaults to "pearson". The other possible values are: "pearson", "spearman", and "poly".}
   \item{sparse}{Boolean. If sparse=TRUE, a sparse model is fitted. If sparse=FALSE, then a non-sparse model is fitted.}
   \item{est}{A character indicating what estimation method will be used. Defaults to "LA" and uses Laplace Approximation. Alternatively, it can be set to "MCMC".}
   \item{full}{Boolean. If full=TRUE, the complete output generated by the estimation method is returned. If full=FALSE, only the samples of the main parameters and the MAP estimates are returned.}
   \item{...}{Further arguments to be passed to `MCMC` or `LA`.}
}
\details{
  This function includes some implementations of Bayesian Gaussian Graphical Models based on the generalized approach proposed by Franco et al. (under review). Currently, there are 8 models implemented:
  * Priors with one parameter for regularization (i.e., models that control the regularization with a single parameter): "normal", "laplace", "logistic", "cauchy", and "hypersec". Respectively, these values set a normal, laplace, logistic, Cauchy, or hyperbolic secant as prior distributions;
  * Priors with two parameters for regularization (i.e., models that control the regularization with two parameters: a "regularization" parameter per se and an "heavy-tailedness" parameter, which may be useful when there are "outlier" correlations): "t", "lomax", "kaniadakis", and "NEG". Respectively, these values set a t, double lomax, or normal-exponential-gamma as prior distributions.
}
\value{
A list of class bggm containing:
1. R_hat, the MAP estimate of the correlation matrix;
2. Rho_hat, the MAP estimate of the partial correlation matrix;
3. sample_R_hat, the posterior samples of the correlation matrix;
4. sample_Rho_hat, the posterior samples of the partial correlation.
5. fit, fit statistics for the model, including: AIC, AICc, CAIC, BIC, SABIC, DIC, and ICOMP.

If full=TRUE, also:
6. full_output, the complete output generated by the `MCMC` function.

And if sparse=TRUE, also:
7. Delta_hat, the MAP estimate of the probability of inclusion of each edge;
8. sample_Delta_hat, the posterior samples of the Delta_hat.
}
\references{
Franco, V. R., Barros, G. W., & Jimenez, M. (2024). A generalized approach for Bayesian Gaussian graphical models. advances.in/psychology. https://doi.org/10.56296/aip00022
}
\examples{##### Fit all models with a toy simulation
## Load the package
require(gbggm)

### Data====
# Seed for reproducibility
set.seed(3)
# Sample size
N <- 200
# Fixed correlations
b1 <- .3; b2 <- .7
# Correlation matrix implied by the chain DAG: x1 -> x2 -> x3
Sigma <- matrix(c(    1, b1, b1*b2,
                     b1,  1,    b2,
                  b1*b2, b2,     1), byrow=TRUE, nrow=3, ncol=3)
# The implied partial correlation matrix
pTrue <- pcor(Sigma)
# The number of variables
V <- ncol(Sigma)
# Random multivariate normal data
X <- MASS::mvrnorm(N, rep(0, V), Sigma, empirical=TRUE)

### FIT GBGGMs====
# Normal prior
fit1 <- gbggm::bggm(X, reg="normal")
# Laplace prior
fit2 <- gbggm::bggm(X, reg="laplace")
# Logistic prior
fit3 <- gbggm::bggm(X, reg="logistic")
# Cauchy prior
fit4 <- gbggm::bggm(X, reg="cauchy")
# Hypersecant prior
fit5 <- gbggm::bggm(X, reg="hypersec")
# Three-parameter t prior
fit6 <- gbggm::bggm(X, reg="t")
# Double lomax prior
fit7 <- gbggm::bggm(X, reg="lomax")
# Kaniadakis prior
fit8 <- gbggm::bggm(X, reg="kaniadakis")
# NEG prior
fit9 <- gbggm::bggm(X, reg="NEG")

### PERFORMANCE COMPARISON====
models <- list(fit1, fit2, fit3, fit4, fit5,
               fit6, fit7, fit8, fit9)
truePartialCor <- pcor(Sigma)[lower.tri(Sigma)]
estimates <- sapply(models, function(g) g$Rho_hat[lower.tri(Sigma)])
modelNames <- c("normal", "laplace", "logistic", 
                "cauchy", "hypersec", "t",
                "lomax", "kaniadakis", "NEG")
data.frame(Models=modelNames,
           MAE=round(colMeans(abs(estimates - truePartialCor)),4),
           round(t(sapply(models, function(g) g$fit)),2))
}
